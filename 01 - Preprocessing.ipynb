{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8ae57f-6a30-4ec3-b392-30a5cb044624",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Chess Position Scanner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c611b901-e0b2-44a5-988c-69146db3e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder, QuantileTransformer, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import PIL\n",
    "import scipy.ndimage as ndimage\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997df762-d424-4945-84f3-35f6671af8cf",
   "metadata": {},
   "source": [
    "## Download the dataset and upack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd26e45-4d00-4d6e-ba39-bf06798e597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download koryakinp/chess-positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8476b765-b10d-4294-b971-3c17c483d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Not unpacking via kaggle cli since the dataset is duplicated\n",
    "archive = zipfile.ZipFile('chess-positions.zip')\n",
    "for file in archive.namelist():\n",
    "    if file.startswith('dataset/'):\n",
    "        archive.extract(file, './')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d3b4b-91cf-4a65-bce2-523508a2cb16",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da58fdb-1acb-4c07-9da6-fc4a582e00eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1b1B1b2/2pK2q1/4p1rB/7k/8/8/3B4/3rb3</td>\n",
       "      <td>./dataset/train/1b1B1b2-2pK2q1-4p1rB-7k-8-8-3B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1b1b1b2/3r4/1rK4b/R7/R2R1k2/2Bp4/2P5/2r5</td>\n",
       "      <td>./dataset/train/1b1b1b2-3r4-1rK4b-R7-R2R1k2-2B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1B1B1K2/3p1N2/6k1/R7/5P2/4q3/7R/1B6</td>\n",
       "      <td>./dataset/train/1B1B1K2-3p1N2-6k1-R7-5P2-4q3-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1b1B1K2/R2B4/7P/3b4/3R2B1/8/3R4/4Qk2</td>\n",
       "      <td>./dataset/train/1b1B1K2-R2B4-7P-3b4-3R2B1-8-3R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1b1b1n2/1K1RN1b1/3pbN2/8/4q1k1/4P3/8/2n3N1</td>\n",
       "      <td>./dataset/train/1b1b1n2-1K1RN1b1-3pbN2-8-4q1k1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>rr4N1/5n2/8/pq3Bk1/1N6/8/2KP4/8</td>\n",
       "      <td>./dataset/train/rr4N1-5n2-8-pq3Bk1-1N6-8-2KP4-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>Rr4Q1/2b5/R1K5/7B/6n1/6q1/R3p1N1/5Rk1</td>\n",
       "      <td>./dataset/train/Rr4Q1-2b5-R1K5-7B-6n1-6q1-R3p1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>rr4rk/1K2N3/8/q7/1n2N3/8/N1Q5/8</td>\n",
       "      <td>./dataset/train/rr4rk-1K2N3-8-q7-1n2N3-8-N1Q5-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>rR4RN/p7/3BR3/8/K7/1B1pB3/1r2k3/B3r3</td>\n",
       "      <td>./dataset/train/rR4RN-p7-3BR3-8-K7-1B1pB3-1r2k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>rr5b/3Q2R1/2K5/4P3/1N3k2/3R2R1/r5p1/7N</td>\n",
       "      <td>./dataset/train/rr5b-3Q2R1-2K5-4P3-1N3k2-3R2R1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              fen  \\\n",
       "0            1b1B1b2/2pK2q1/4p1rB/7k/8/8/3B4/3rb3   \n",
       "1        1b1b1b2/3r4/1rK4b/R7/R2R1k2/2Bp4/2P5/2r5   \n",
       "2             1B1B1K2/3p1N2/6k1/R7/5P2/4q3/7R/1B6   \n",
       "3            1b1B1K2/R2B4/7P/3b4/3R2B1/8/3R4/4Qk2   \n",
       "4      1b1b1n2/1K1RN1b1/3pbN2/8/4q1k1/4P3/8/2n3N1   \n",
       "...                                           ...   \n",
       "79995             rr4N1/5n2/8/pq3Bk1/1N6/8/2KP4/8   \n",
       "79996       Rr4Q1/2b5/R1K5/7B/6n1/6q1/R3p1N1/5Rk1   \n",
       "79997             rr4rk/1K2N3/8/q7/1n2N3/8/N1Q5/8   \n",
       "79998        rR4RN/p7/3BR3/8/K7/1B1pB3/1r2k3/B3r3   \n",
       "79999      rr5b/3Q2R1/2K5/4P3/1N3k2/3R2R1/r5p1/7N   \n",
       "\n",
       "                                                    path  \n",
       "0      ./dataset/train/1b1B1b2-2pK2q1-4p1rB-7k-8-8-3B...  \n",
       "1      ./dataset/train/1b1b1b2-3r4-1rK4b-R7-R2R1k2-2B...  \n",
       "2      ./dataset/train/1B1B1K2-3p1N2-6k1-R7-5P2-4q3-7...  \n",
       "3      ./dataset/train/1b1B1K2-R2B4-7P-3b4-3R2B1-8-3R...  \n",
       "4      ./dataset/train/1b1b1n2-1K1RN1b1-3pbN2-8-4q1k1...  \n",
       "...                                                  ...  \n",
       "79995  ./dataset/train/rr4N1-5n2-8-pq3Bk1-1N6-8-2KP4-...  \n",
       "79996  ./dataset/train/Rr4Q1-2b5-R1K5-7B-6n1-6q1-R3p1...  \n",
       "79997  ./dataset/train/rr4rk-1K2N3-8-q7-1n2N3-8-N1Q5-...  \n",
       "79998  ./dataset/train/rR4RN-p7-3BR3-8-K7-1B1pB3-1r2k...  \n",
       "79999  ./dataset/train/rr5b-3Q2R1-2K5-4P3-1N3k2-3R2R1...  \n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def path_to_fen(path):\n",
    "    filename = os.path.basename(path).split('.')[0]\n",
    "    fen = filename.replace('-', '/')\n",
    "    return fen\n",
    "\n",
    "def get_dataset(prefix):\n",
    "    files = glob.glob(prefix)\n",
    "    fen = [path_to_fen(path) for path in files]\n",
    "    return pd.DataFrame({'fen': fen, 'path': files})\n",
    "\n",
    "train = get_dataset('./dataset/train/*')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e580094-3f5d-406e-9b1d-53a44b222fa3",
   "metadata": {},
   "source": [
    "## FEN and Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2f32df-affb-4572-b838-fcd9c62c0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = {'0', '1', '2', '3', '4', '5', '6', '7', '8'}\n",
    "def decompress_fen(fen):\n",
    "    return ''.join([\n",
    "        ' ' * int(ch) if ch in digits else ch\n",
    "        for ch in fen\n",
    "    ]).split('/')\n",
    "\n",
    "def load_image(filename):\n",
    "    img = PIL.Image.open(filename)\n",
    "    bw = img.convert('L')\n",
    "    img_array = np.asarray(bw)\n",
    "    return img_array\n",
    "\n",
    "def segment_image(img, n=8):\n",
    "    return np.array(np.split(np.array(np.split(img, n, 1)), n, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaba26-7ecb-40a1-9863-cfea4ce45d57",
   "metadata": {},
   "source": [
    "## Tile dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0e343a-e765-446d-bb75-7058f50118bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "79995    None\n",
       "79996    None\n",
       "79997    None\n",
       "79998    None\n",
       "79999    None\n",
       "Name: path, Length: 80000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs('./dataset_pieces', exist_ok=True)\n",
    "classes = [\n",
    "    'p', 'b', 'n', 'r', 'k', 'q',\n",
    "    'P', 'B', 'N', 'R', 'K', 'Q',\n",
    "    'Empty',\n",
    "]\n",
    "for class_name in classes:\n",
    "    os.makedirs('./dataset_pieces/class_'+class_name, exist_ok=True)\n",
    "\n",
    "class_counters = {\n",
    "    class_name: 0\n",
    "    for class_name in classes\n",
    "}\n",
    "\n",
    "def process_board(path, verbose=False):\n",
    "    if verbose:\n",
    "        print('Processing ' + path)\n",
    "    \n",
    "    img = load_image(path)\n",
    "    tiles = segment_image(img)\n",
    "    \n",
    "    fen = path_to_fen(path)\n",
    "    board = decompress_fen(fen)\n",
    "\n",
    "    n = 8\n",
    "    empty_space_counter = 0\n",
    "    empty_space_max = 10\n",
    "    for y in range(n):\n",
    "        for x in range(n):\n",
    "            figure = board[y][x]\n",
    "            \n",
    "            if figure == ' ':\n",
    "                figure = 'Empty'\n",
    "\n",
    "                if (y + x) % 2 != empty_space_counter % 2:\n",
    "                    continue\n",
    "                \n",
    "                empty_space_counter += 1\n",
    "\n",
    "                if empty_space_counter >= empty_space_max:\n",
    "                    continue\n",
    "\n",
    "            class_counters[figure] += 1\n",
    "            id = class_counters[figure]\n",
    "            figure_img = PIL.Image.fromarray(tiles[y][x])\n",
    "            figure_img.save(f'./dataset_pieces/class_{figure}/{figure}_image_{id}.jpeg')\n",
    "            \n",
    "train.path.apply(process_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8487b9c-d807-4495-9cbb-05b96fe5898e",
   "metadata": {},
   "source": [
    "## Balanced, sampled tile dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea464484-7e4b-457c-915b-2ed6305b52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeded sample \n",
    "rng = random.Random(42)\n",
    "\n",
    "classes = [\n",
    "    'p', 'b', 'n', 'r', 'k', 'q',\n",
    "    'P', 'B', 'N', 'R', 'K', 'Q',\n",
    "    'Empty',\n",
    "]\n",
    "for class_name in classes:\n",
    "    class_folder = './dataset_pieces_sampled/class_'+class_name\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    sample = rng.sample(glob.glob(f'dataset_pieces/class_{class_name}/*'), 10000)\n",
    "    for id, file in enumerate(sample):\n",
    "        shutil.copyfile(file, f'{class_folder}/{class_name}_image_{id}.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c3072-accc-403a-a42a-9d73c36835d1",
   "metadata": {},
   "source": [
    "## Color and Figure type dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df11e86-88f5-4fbf-af51-c0172ee2f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_label(path):\n",
    "    filename = os.path.basename(path)\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "def make_piece_dataset(in_path, out_path):\n",
    "    classes = ['p', 'b', 'n', 'r', 'q', 'k', 'empty']\n",
    "    class_counters = {\n",
    "        classname: 0\n",
    "        for classname in classes\n",
    "    }\n",
    "    \n",
    "    for classname in classes:\n",
    "        os.makedirs(out_path + f'/class_{classname}/', exist_ok=True)\n",
    "        \n",
    "    for file in glob.glob(in_path + '/**/*.jpeg'):\n",
    "        new_label = path_to_label(file).lower()\n",
    "        class_counters[new_label] += 1\n",
    "        id = class_counters[new_label]\n",
    "        shutil.copy(file, out_path+f'/class_{new_label}/{new_label}_image_{id}.jpeg')\n",
    "\n",
    "    # Add 10k more empty tiles to rebalance\n",
    "    rng = random.Random(123)\n",
    "    sample = rng.sample(glob.glob(f'./dataset_pieces/class_Empty/*'), 10000)\n",
    "    for id, file in enumerate(sample):\n",
    "        shutil.copyfile(file, f'{out_path}/class_empty/empty_image_{id+10001}.jpeg')\n",
    "\n",
    "def make_color_dataset(in_path, out_path):\n",
    "    classes = ['black', 'white']\n",
    "    class_counters = {\n",
    "        classname: 0\n",
    "        for classname in classes\n",
    "    }\n",
    "    \n",
    "    for classname in classes:\n",
    "        os.makedirs(out_path + f'/class_{classname}/', exist_ok=True)\n",
    "        \n",
    "    for file in glob.glob(in_path + '/**/*.jpeg'):\n",
    "        old_label = path_to_label(file)\n",
    "        if old_label == 'Empty':\n",
    "            continue\n",
    "        new_label = 'white' if old_label.isupper() else 'black' \n",
    "        class_counters[new_label] += 1\n",
    "        id = class_counters[new_label]\n",
    "        shutil.copy(file, out_path+f'/class_{new_label}/{new_label}_image_{id}.jpeg')\n",
    "\n",
    "# TODO: Use globals\n",
    "make_piece_dataset('./dataset_pieces_sampled', './dataset_figures_only_sampled')\n",
    "make_color_dataset('./dataset_pieces_sampled', './dataset_color_only_sampled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
